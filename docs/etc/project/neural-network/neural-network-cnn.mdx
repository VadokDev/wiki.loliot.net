---
id: neural-network-cnn
title: Neural Network CNN(Convolution)
sidebar_label: CNN(Convolution)
description: Neural Network CNN(Convolution)
keywords:
  - Neural Network
  - Convolution
---

import useBaseUrl from "@docusaurus/useBaseUrl";

<link rel="stylesheet" href={useBaseUrl("katex/katex.min.css")} />

<center>
  <img
    src={useBaseUrl(
      "img/etc/project/neural-network/neural-network-cnn-example.png"
    )}
  />
</center>

$$
z^l_{i,j} = \sum_m \sum_n{a^{l-1}_{i+m,j+n} (\omega')^l_{m,n} + b^l_{i,j}}
$$

$$
A^l = \sigma (Z^l) = \sigma ( A^{l-1} * W^l + B^l )
$$

# Convolution

$$
K, K' \isin \R^{M \times N} \quad K(m, n) = K'(M-1-m, N-1-n)
$$

$$
\begin{aligned}
( I * K )_{ij}
&= \sum_m \sum_n {I(i+m, j+n)K(M-1-m, N-1-n)} \\
&= \sum_m \sum_n {I(i+m, j+n)K'(m, n)} &= (I \otimes K')_{ij}
\end{aligned}
$$

:::info
In the CNN description, most of the picture representing convolution seem to the cross-correlation using $K'$.
:::

## Kernel example

$$
K = \begin{bmatrix}1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9\end{bmatrix} \quad
K' = \begin{bmatrix}9 & 8 & 7 \\ 6 & 5 & 4 \\ 3 & 2 & 1\end{bmatrix}
$$

# Back-propagation

$$
\delta^l_{i,j} \equiv \frac{\partial C}{\partial z^l_{i,j}}
$$

$$
\begin{aligned}
\delta^l_{i,j} = \frac{\partial C}{\partial z^l_{i,j}}
&= \sum_x \sum_y {
  \frac { \partial C } { \partial z^{l+1}_{x,y} }
  \frac { \partial z^{l+1}_{x,y} } { \partial z^l_{i,j} }
  } \\
&= \sum_x \sum_y {
  \delta^{l+1}_{x,y} (\omega')^{l+1}_{i-x,j-y} \sigma' (z^l_{i,j})
  } \\
&= \sum_m \sum_n {
  \delta^{l+1}_{i-m,j-n} (\omega')^{l+1}_{m,n} \sigma' (z^l_{i,j})
  }
\end{aligned}
$$

$$
\begin{aligned}
\frac {\partial C} {\partial (\omega')^l_{m,n}}
&= \sum_i \sum_j {
  \frac { \partial C } { \partial z^{l}_{i,j} }
  \frac { \partial z^{l}_{i,j} } { \partial ( \omega' )^l_{m,n} }
  } \\
&= \sum_i \sum_j {
  \delta^l_{i,j} a^{l-1}_{i+m, j+n}
  }
\end{aligned}
$$

$$
\begin{aligned}
\frac {\partial C} {\partial b^l_{i,j}}
&= \sum_x \sum_y {
  \frac { \partial C } { \partial z^{l}_{x,y} }
  \frac { \partial z^{l}_{x,y} } { \partial b^l_{i,j} }
  } \\
& = \delta^l_{i,j}
\end{aligned}
$$

# TensorFlow example

## Training

```python title="hong_net_5.py"
import tensorflow as tf
import numpy as np

mnist = tf.keras.datasets.mnist
"""
x: gray scale handwritten digits
y: label
x_train[0].shape == (28, 28)
y_train[0] == 5
len(x_train) == 60000
len(x_test) == 10000
"""
(x_train, y_train), (x_test, y_test) = mnist.load_data()
# image, image_row, image_col => (32,32)
x_train = np.pad(x_train, ((0, 0), (2, 2), (2, 2)), mode="constant")
x_test = np.pad(x_test, ((0, 0), (2, 2), (2, 2)), mode="constant")
# Add channels
x_train = x_train.reshape(*x_train.shape, 1)
x_test = x_test.reshape(*x_test.shape, 1)
# Type cast
x_train = x_train.astype("float32")
x_test = x_test.astype("float32")


class HongNet5(tf.keras.Model):
    def __init__(self):
        super(HongNet5, self).__init__()
        """
        filters: Integer, the dimensionality of the output space.
        kernel_size: An integer or tuple/list of 2 integers, specifying the
            height and width of the 2D convolution window. Can be a single
            integer to specify the same value for all spatial dimensions.
        activation: Activation function to use.
        Input shape: (batch_size, rows, cols, channels)
        Output shape: (batch_size, rows, cols, filters)
        """
        self.conv1 = tf.keras.layers.Conv2D(
            filters=6, kernel_size=5, activation="relu"
        )
        self.avgPool1 = tf.keras.layers.AveragePooling2D()
        self.conv2 = tf.keras.layers.Conv2D(
            filters=16, kernel_size=5, activation="relu"
        )
        self.avgPool2 = tf.keras.layers.AveragePooling2D()
        self.conv3 = tf.keras.layers.Conv2D(
            filters=120, kernel_size=5, activation="relu"
        )
        self.flatten = tf.keras.layers.Flatten()
        """
        units: Positive integer, dimensionality of the output space.
        """
        self.d1 = tf.keras.layers.Dense(84, activation="relu")
        self.d2 = tf.keras.layers.Dense(10, activation="softmax")

    def call(self, x):
        x = self.conv1(x)
        x = self.avgPool1(x)
        x = self.conv2(x)
        x = self.avgPool2(x)
        x = self.conv3(x)
        x = self.flatten(x)
        x = self.d1(x)
        x = self.d2(x)
        return x


model = HongNet5()

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)

model.fit(
    x_train, y_train, epochs=5, validation_data=(x_test, y_test),
)

model.summary()

score = model.evaluate(x_test, y_test, verbose=1)
print("Test loss:", score[0])
print("Test accuracy: {}%".format(score[1] * 100))

model.save("hong_net_5")

run_model = tf.function(lambda x: model(x))
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec((1, *x_train.shape[1:]), x_train.dtype)
)
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)

np.save("x_test.npy", x_test)
np.save("y_test.npy", y_test)
```

## Inference

```python title="inference.py"
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import time

x_test = np.load("x_test.npy")
y_test = np.load("y_test.npy")

model = tf.keras.models.load_model("hong_net_5")

for _ in range(5):
    num = int(np.random.rand(1) * 10000)
    img = x_test[num].reshape((32, 32))
    ret = model.predict(x_test[num : num + 1])
    inference = np.argmax(ret)
    print("{}: {}".format(inference, inference == y_test[num]))
    plt.imshow(img)
    plt.show()
```

```python title="inference_tflite.py"
import tflite_runtime.interpreter as tflite
import numpy as np
import matplotlib.pyplot as plt
import time

x_test = np.load("x_test.npy")
y_test = np.load("y_test.npy")

interpreter = tflite.Interpreter(model_path="converted_model.tflite")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
input_shape = input_details[0]["shape"]

output_details = interpreter.get_output_details()

for _ in range(5):
    num = int(np.random.rand(1) * 10000)
    img = x_test[num].reshape((32, 32))
    interpreter.set_tensor(input_details[0]["index"], x_test[num : num + 1])
    interpreter.invoke()
    output_data = interpreter.get_tensor(output_details[0]["index"])
    inference = np.argmax(output_data)
    print("{}: {}".format(inference, inference == y_test[num]))
    plt.imshow(img)
    plt.show()
```

# Reference

- [https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/](https://www.jefkine.com/general/2016/09/05/backpropagation-in-convolutional-neural-networks/)
- [https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215)
- Gradient-Based Learning Applied to Document Recognition(LeNet 5)
- [https://www.thelearningmachine.ai/cnn](https://www.thelearningmachine.ai/cnn)
